현재 분석 코드를 확인했습니다. 네 가지 질문에 대해 하나씩 답변드리겠습니다.

---

## 1. 분석 리포트 품질을 올리는 방법

현재 분석은 **단일 AI 호출 → JSON 반환**으로 이루어져 있습니다. 품질을 올릴 수 있는 방법이 여러 가지 있습니다.

### A. 다단계 분석 (Multi-pass)

현재는 한 번에 모든 것(요약+쟁점+타임라인+증거+모순점)을 뽑고 있는데, 이걸 나누면 각 단계의 품질이 올라갑니다.

```
[현재]  문서 전체 → AI 1회 호출 → 전체 결과 JSON

[개선]  문서 전체 → 1차: 요약+쟁점 → 2차: 타임라인 → 3차: 증거+모순점
        각 단계가 이전 단계 결과를 참고
```

비용 증가는 있지만 Gemini Flash 기준 건당 ~2원 → ~6원 정도로, 여전히 매우 저렴합니다. 한 번에 너무 많은 것을 요구하면 모델이 "적당히" 하게 되는데, 쪼개면 각 항목의 **깊이**가 달라집니다.

### B. 증거기록 분류 결과 더 적극 활용

이미 증거기록 분류·개별 분석이 있으니, 통합 분석 때 이 결과를 **구조화된 형태**로 제공하면 품질이 오릅니다.

```
[현재]  증거 섹션 원문 발췌 + JSON 덤프를 통째로 삽입

[개선]  "진술조서 3건의 핵심 진술 요약"
        "물증 2건의 증거능력 평가"
        → 정리된 형태로 삽입하여 AI가 더 잘 활용
```

### C. 페이지 단위 분석 후 종합

수사기록이 수백 페이지일 때, 200,000자로 잘라서 한 번에 보내는 것보다 **페이지 그룹별로 분석 → 종합**이 더 정확합니다.

```
p.1-50 → 부분 분석 → ┐
p.51-100 → 부분 분석 → ├→ 종합 분석
p.101-150 → 부분 분석 → ┘
```

### D. 프롬프트 고도화

현재 프롬프트에 추가하면 좋을 것:
- **구체적 법률 프레임워크 제시**: "증거능력 판단 시 위법수집증거 배제법칙(형소법 308조의2) 적용 여부 검토" 같은 구체적 기준
- **분석 깊이 지시**: "각 쟁점에 대해 검찰 측 주장, 방어 측 반론, 예상 법원 판단을 각각 서술"
- **출력 품질 기준**: "타임라인은 최소 10개 이상 이벤트, 모순점은 직접인용 포함"

---

## 2. 정확도 검증 / 할루시네이션 방지

이게 가장 중요한 부분입니다. 현재는 AI가 반환한 것을 **그대로 신뢰**하고 있습니다.

### A. 페이지 번호 검증 (프로그래밍적으로 가능)

AI가 "p.15에 OO 진술이 있다"고 했을 때, 실제로 `_pages.json`의 15페이지 텍스트에 관련 내용이 있는지 **코드로 확인**할 수 있습니다.

```
AI 분석 결과의 각 항목 → 코드가 page 번호 추출
→ _pages.json에서 해당 페이지 텍스트 가져옴
→ 키워드/문장 매칭으로 근거 존재 여부 확인
→ 검증 결과를 리포트에 표시: ✅ 확인됨 / ⚠️ 미확인
```

이건 **AI 호출 없이** 코드만으로 가능합니다. 비용 0원.

### B. 직접 인용(Grounding) 강제

프롬프트에 "각 주장에 대해 원문에서 직접 인용구를 포함하라"고 지시하면, AI가 만들어낸 내용인지 실제 원문 기반인지 확인할 수 있습니다.

```json
{
  "event": "피의자가 현장에서 도주",
  "page": 15,
  "quote": "피의자 김OO은 경찰관이 도착하기 전 현장을 이탈하였다"  // ← 원문 인용
}
```

인용구가 실제 해당 페이지에 있는지 코드로 검증 가능합니다.

### C. 신뢰도 점수

AI에게 각 항목의 확신도를 함께 출력하게 합니다.

```json
{
  "event": "피의자가 현장에서 도주",
  "page": 15,
  "confidence": "high",       // high / medium / low
  "basis": "피의자신문조서 직접 기재"  // 근거 유형
}
```

`confidence: low`인 항목은 리포트에서 별도 표시 → 사용자가 직접 확인하도록 유도.

### D. 후처리 검증 파이프라인

```
AI 분석 완료
  ↓
[검증 1] 페이지 번호 범위 체크 (문서 총 페이지 초과하는 번호 제거)
  ↓
[검증 2] 날짜 유효성 체크 (미래 날짜, 비현실적 날짜 플래그)
  ↓
[검증 3] 인물명 일관성 체크 (같은 사람인데 다른 이름으로 나온 것 병합)
  ↓
[검증 4] 페이지 번호-원문 매칭 (A에서 설명한 방법)
  ↓
검증된 분석 결과 + 검증 리포트
```

검증 1~3은 **코드만으로 가능(비용 0원)**, 검증 4도 문자열 매칭이므로 비용 0원.

---

## 3. 다양한 입력 형식

현재는 PDF만 지원합니다. 추가 가능한 형식과 난이도를 정리하면:

| 형식 | 중요도 | 난이도 | 방법 |
|------|--------|--------|------|
| **HWP (한글 파일)** | **최상** | 중간 | `hwp.js` 또는 LibreOffice 서버 변환. **한국 법률에서 가장 많이 쓰는 형식** |
| **DOCX (Word)** | 높음 | 낮음 | `mammoth` 라이브러리로 텍스트 추출. npm 패키지 하나면 됨 |
| **TXT / 일반 텍스트** | 중간 | 매우 낮음 | 그대로 읽으면 됨 |
| **이미지 (JPG/PNG)** | 중간 | 낮음 | 이미 Vision 기능 있음. OCR 경로 활용 |
| **녹취록 (SRT/VTT)** | 낮음 | 낮음 | 자막 파서로 텍스트 추출 |
| **이메일 (EML)** | 낮음 | 중간 | `mailparser` 라이브러리 |
| **음성 파일 (MP3/WAV)** | 낮음 | 높음 | Whisper API 또는 Google STT. 비용 발생 |

**핵심**: 한국 법률 실무에서는 **HWP**가 압도적으로 중요합니다. 법원 판결문, 검찰 수사기록 요약, 변호사 서면 모두 HWP로 작성됩니다. HWP 지원은 경쟁력에 직결됩니다.

DOCX는 `mammoth` 패키지 하나로 즉시 구현 가능하고, HWP는 `hwp.js`(오픈소스)로 텍스트 추출이 가능합니다. 두 가지 모두 비용 0원이고 구현 난이도가 높지 않습니다.

---

## 4. 다음 스텝 제안

"분석 파이프라인이 핵심 가치"라는 전략 방향에 맞춰 우선순위를 잡으면:

### 즉시 (베타 전)

| 순위 | 작업 | 이유 | 난이도 |
|------|------|------|--------|
| **1** | **분석 리포트 PDF 다운로드** | 핵심 전환 기능. 이게 없으면 전략 자체가 작동 안 함 | 중간 |
| **2** | **프롬프트 템플릿 시스템** | 의견서·변론요지서 등 템플릿 + 데이터 삽입 | 낮음 |
| **3** | **페이지 번호 검증 (후처리)** | 비용 0원으로 정확도를 크게 올릴 수 있음 | 낮음 |

### 단기 (베타 초기)

| 순위 | 작업 | 이유 |
|------|------|------|
| **4** | **HWP 입력 지원** | 한국 법률 실무 필수. 이거 없으면 "PDF로 변환해서 올려야 하네" → 이탈 |
| **5** | **직접 인용(quote) + 신뢰도 점수** | 프롬프트 수정만으로 구현 가능 |
| **6** | **다단계 분석** | 분석 품질 체감 향상 |

### 추천하는 **바로 다음 스텝**

**1번: 분석 리포트 PDF 다운로드 구현**

이것이 전략 전환의 핵심이고, 이게 있어야 "분석은 ASSO, 서면은 사용자의 AI"라는 워크플로우가 완성됩니다. `jspdf` 또는 `@react-pdf/renderer` 등으로 클라이언트 사이드에서 구현 가능하고, 서버 비용도 들지 않습니다.

어떤 것부터 진행할까요?